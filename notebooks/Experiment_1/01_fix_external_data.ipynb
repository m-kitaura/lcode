{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:35.188068Z",
     "iopub.status.busy": "2021-07-05T12:34:35.188068Z",
     "iopub.status.idle": "2021-07-05T12:34:36.003307Z",
     "shell.execute_reply": "2021-07-05T12:34:36.002305Z",
     "shell.execute_reply.started": "2021-07-05T12:34:35.188068Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:36.004370Z",
     "iopub.status.busy": "2021-07-05T12:34:36.004370Z",
     "iopub.status.idle": "2021-07-05T12:34:37.827430Z",
     "shell.execute_reply": "2021-07-05T12:34:37.827430Z",
     "shell.execute_reply.started": "2021-07-05T12:34:36.004370Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:37.827430Z",
     "iopub.status.busy": "2021-07-05T12:34:37.827430Z",
     "iopub.status.idle": "2021-07-05T12:34:37.979748Z",
     "shell.execute_reply": "2021-07-05T12:34:37.978467Z",
     "shell.execute_reply.started": "2021-07-05T12:34:37.827430Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(EXTERNAL_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(BASE_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(INTERIM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate data and drop nonnumerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:37.982859Z",
     "iopub.status.busy": "2021-07-05T12:34:37.981151Z",
     "iopub.status.idle": "2021-07-05T12:34:38.121362Z",
     "shell.execute_reply": "2021-07-05T12:34:38.120366Z",
     "shell.execute_reply.started": "2021-07-05T12:34:37.982859Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'Anuran_Calls'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'Frogs_MFCCs.csv'))\n",
    "    df['label'] = df['Family']\n",
    "    df = df.drop(['Family', 'Genus', 'Species', 'RecordID'], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.122797Z",
     "iopub.status.busy": "2021-07-05T12:34:38.122797Z",
     "iopub.status.idle": "2021-07-05T12:34:38.301305Z",
     "shell.execute_reply": "2021-07-05T12:34:38.300309Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.122797Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'avila'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df_tr = pd.read_csv(os.path.join(dataset_path, 'avila-tr.txt'), header=None)\n",
    "    df_ts = pd.read_csv(os.path.join(dataset_path, 'avila-ts.txt'), header=None)\n",
    "    df = pd.concat([df_tr, df_ts])\n",
    "    cols = ['intercolumnar distance', 'upper margin', 'lower margin', 'exploitation', 'row number', \n",
    "            'modular ratio', 'interlinear spacing', 'weight', 'peak number', 'MR/IS', 'label']\n",
    "    df.columns = cols\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.303307Z",
     "iopub.status.busy": "2021-07-05T12:34:38.303307Z",
     "iopub.status.idle": "2021-07-05T12:34:38.470733Z",
     "shell.execute_reply": "2021-07-05T12:34:38.469766Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.303307Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'Cardiotocography'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_excel(os.path.join(dataset_path, 'CTG.xls'), sheet_name='Data', header=1)\n",
    "    cols = pd.read_excel(os.path.join(dataset_path, 'CTG.xls'), sheet_name='Data', header=None)[:1].dropna(axis=1).columns.tolist()\n",
    "    df = df.iloc[:, cols].dropna()\n",
    "    df['label'] = df['NSP']\n",
    "    df = df.drop(['CLASS', 'NSP'], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.470733Z",
     "iopub.status.busy": "2021-07-05T12:34:38.470733Z",
     "iopub.status.idle": "2021-07-05T12:34:38.626495Z",
     "shell.execute_reply": "2021-07-05T12:34:38.625325Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.470733Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'credit card'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_excel(os.path.join(dataset_path, 'default of credit card clients.xls'), sheet_name='Data', header=1)\n",
    "    df['label'] = df['default payment next month']\n",
    "    df = df.drop(['ID', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
    "                  'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'default payment next month'], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.626495Z",
     "iopub.status.busy": "2021-07-05T12:34:38.626495Z",
     "iopub.status.idle": "2021-07-05T12:34:38.754110Z",
     "shell.execute_reply": "2021-07-05T12:34:38.754110Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.626495Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'EEG'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'EEG Eye State.arff'), header=None, skiprows=19)\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.756794Z",
     "iopub.status.busy": "2021-07-05T12:34:38.755792Z",
     "iopub.status.idle": "2021-07-05T12:34:38.894551Z",
     "shell.execute_reply": "2021-07-05T12:34:38.893590Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.756794Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'HTRU2'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'HTRU_2.csv'), header=None)\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:38.895589Z",
     "iopub.status.busy": "2021-07-05T12:34:38.895589Z",
     "iopub.status.idle": "2021-07-05T12:34:39.044534Z",
     "shell.execute_reply": "2021-07-05T12:34:39.043531Z",
     "shell.execute_reply.started": "2021-07-05T12:34:38.895589Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'image'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df_data = pd.read_csv(os.path.join(dataset_path, 'segmentation.data'), header=2)\n",
    "    df_test = pd.read_csv(os.path.join(dataset_path, 'segmentation.test'), header=2)\n",
    "    df = pd.concat([df_data, df_test])\n",
    "    df['label'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.047531Z",
     "iopub.status.busy": "2021-07-05T12:34:39.047531Z",
     "iopub.status.idle": "2021-07-05T12:34:39.189832Z",
     "shell.execute_reply": "2021-07-05T12:34:39.188832Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.047531Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'landsat'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df_tr = pd.read_csv(os.path.join(dataset_path, 'sat.trn'), header=None, sep=' ')\n",
    "    df_ts = pd.read_csv(os.path.join(dataset_path, 'sat.tst'), header=None, sep=' ')\n",
    "    df = pd.concat([df_tr, df_ts])\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.191887Z",
     "iopub.status.busy": "2021-07-05T12:34:39.191887Z",
     "iopub.status.idle": "2021-07-05T12:34:39.400832Z",
     "shell.execute_reply": "2021-07-05T12:34:39.399765Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.191887Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'letter-recognition'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'letter-recognition.data'), header=None)\n",
    "    cols = ['label', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar',\n",
    "            'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
    "    df.columns = cols\n",
    "    df = df.loc[:, cols[1:] + ['label']]\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.403862Z",
     "iopub.status.busy": "2021-07-05T12:34:39.403862Z",
     "iopub.status.idle": "2021-07-05T12:34:39.558700Z",
     "shell.execute_reply": "2021-07-05T12:34:39.557648Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.403862Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'magic'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'magic04.data'), header=None)\n",
    "    df.columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.558700Z",
     "iopub.status.busy": "2021-07-05T12:34:39.558700Z",
     "iopub.status.idle": "2021-07-05T12:34:39.722089Z",
     "shell.execute_reply": "2021-07-05T12:34:39.721092Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.558700Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'occupancy'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df1 = pd.read_csv(os.path.join(dataset_path, 'datatest.txt'))\n",
    "    df2 = pd.read_csv(os.path.join(dataset_path, 'datatest2.txt'))\n",
    "    df3 = pd.read_csv(os.path.join(dataset_path, 'datatraining.txt'))\n",
    "    df = pd.concat([df1, df2, df3])\n",
    "    df = df.drop(['date'], axis=1)\n",
    "    df.columns = df.columns[:-1].tolist() + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.724048Z",
     "iopub.status.busy": "2021-07-05T12:34:39.724048Z",
     "iopub.status.idle": "2021-07-05T12:34:39.888936Z",
     "shell.execute_reply": "2021-07-05T12:34:39.887934Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.724048Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'page-blocks'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_fwf(os.path.join(dataset_path, 'page-blocks.data'), header=None)\n",
    "    df.columns = ['height', 'lenght', 'area', 'eccen', 'p_black', 'p_and', 'mean_tr', 'blackpix', 'blackand', 'wb_trans', 'label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:39.889936Z",
     "iopub.status.busy": "2021-07-05T12:34:39.889936Z",
     "iopub.status.idle": "2021-07-05T12:34:40.033927Z",
     "shell.execute_reply": "2021-07-05T12:34:40.031678Z",
     "shell.execute_reply.started": "2021-07-05T12:34:39.889936Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'pendigits'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df1 = pd.read_csv(os.path.join(dataset_path, 'pendigits.tes'), header=None)\n",
    "    df2 = pd.read_csv(os.path.join(dataset_path, 'pendigits.tra'), header=None)\n",
    "    df = pd.concat([df1, df2])\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.041489Z",
     "iopub.status.busy": "2021-07-05T12:34:40.041489Z",
     "iopub.status.idle": "2021-07-05T12:34:40.226217Z",
     "shell.execute_reply": "2021-07-05T12:34:40.225218Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.041489Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'shuttle'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df_trn = pd.read_csv(os.path.join(dataset_path, 'shuttle.trn'), header=None, sep=' ')\n",
    "    df_tst = pd.read_csv(os.path.join(dataset_path, 'shuttle.tst'), header=None, sep=' ')\n",
    "    df = pd.concat([df_trn, df_tst])\n",
    "    cols = ['feat%d'%i for i in range(9)] + ['label']\n",
    "    df.columns = cols\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.229218Z",
     "iopub.status.busy": "2021-07-05T12:34:40.228215Z",
     "iopub.status.idle": "2021-07-05T12:34:40.380019Z",
     "shell.execute_reply": "2021-07-05T12:34:40.378829Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.228215Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'Wall-following'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'sensor_readings_24.data'), header=None)\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.382521Z",
     "iopub.status.busy": "2021-07-05T12:34:40.380019Z",
     "iopub.status.idle": "2021-07-05T12:34:40.527827Z",
     "shell.execute_reply": "2021-07-05T12:34:40.526511Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.382023Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'wifi_localization'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df = pd.read_fwf(os.path.join(dataset_path, 'wifi_localization.txt'), header=None)\n",
    "    df.columns = ['feat%d'%i for i in range(len(df.columns)-1)] + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.529856Z",
     "iopub.status.busy": "2021-07-05T12:34:40.529856Z",
     "iopub.status.idle": "2021-07-05T12:34:40.681104Z",
     "shell.execute_reply": "2021-07-05T12:34:40.680052Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.529856Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'wine'\n",
    "\n",
    "save_path = os.path.join(BASE_DATA_DIR, dataset_name+'.csv')\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_path = os.path.join(EXTERNAL_DATA_DIR, dataset_name)\n",
    "    df_red = pd.read_csv(os.path.join(dataset_path, 'winequality-red.csv'), sep=';')\n",
    "    df_wit = pd.read_csv(os.path.join(dataset_path, 'winequality-white.csv'), sep=';')\n",
    "    df = pd.concat([df_red, df_wit])\n",
    "    df.columns = df.columns[:-1].tolist() + ['label']\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization by RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.684183Z",
     "iopub.status.busy": "2021-07-05T12:34:40.682534Z",
     "iopub.status.idle": "2021-07-05T12:34:40.829217Z",
     "shell.execute_reply": "2021-07-05T12:34:40.828676Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.684116Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    rs = RobustScaler()\n",
    "    rs.fit(df)\n",
    "    norm_val = rs.transform(df)\n",
    "    label = df.iloc[:, -1].values\n",
    "    df = pd.DataFrame(norm_val[:, :-1], columns=df.columns[:-1])\n",
    "    df['label'] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:40.831773Z",
     "iopub.status.busy": "2021-07-05T12:34:40.830801Z",
     "iopub.status.idle": "2021-07-05T12:34:41.007184Z",
     "shell.execute_reply": "2021-07-05T12:34:41.006098Z",
     "shell.execute_reply.started": "2021-07-05T12:34:40.831773Z"
    }
   },
   "outputs": [],
   "source": [
    "def plt_feature_range(df):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    sns.boxplot(data=df, linewidth=1, orient='h', ax=ax[0], showfliers=False)\n",
    "    sns.boxplot(data=df, linewidth=1, orient='h', ax=ax[1])\n",
    "    ax[0].set_title('without outliers')\n",
    "    ax[1].set_title('with outliers')\n",
    "    plt.suptitle('range of feature values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.007184Z",
     "iopub.status.busy": "2021-07-05T12:34:41.007184Z",
     "iopub.status.idle": "2021-07-05T12:34:41.164316Z",
     "shell.execute_reply": "2021-07-05T12:34:41.162982Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.007184Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_normed_dataset(dataset_name, show_range=True):\n",
    "    save_path = os.path.join(INTERIM_DATA_DIR, dataset + '_norm.csv')\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "\n",
    "    path = os.path.join(BASE_DATA_DIR, dataset_name + '.csv')\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    label_names = df['label'].astype('category').cat.categories\n",
    "    print(label_names)\n",
    "    df['label'] = df['label'].astype('category').cat.codes\n",
    "\n",
    "    if show_range:\n",
    "        plt_feature_range(df.iloc[:, :-1])\n",
    "    df = norm(df)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    if show_range:\n",
    "        plt_feature_range(df.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.166244Z",
     "iopub.status.busy": "2021-07-05T12:34:41.165208Z",
     "iopub.status.idle": "2021-07-05T12:34:41.334136Z",
     "shell.execute_reply": "2021-07-05T12:34:41.331932Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.166244Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ['Anuran_Calls', 'avila', 'Cardiotocography', 'credit card', 'EEG', 'HTRU2',\n",
    "            'image', 'landsat', 'letter-recognition', 'magic', 'occupancy', 'page-blocks',\n",
    "            'pendigits', 'shuttle', 'Wall-following', 'wifi_localization', 'wine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.338509Z",
     "iopub.status.busy": "2021-07-05T12:34:41.337369Z",
     "iopub.status.idle": "2021-07-05T12:34:41.511663Z",
     "shell.execute_reply": "2021-07-05T12:34:41.511663Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.338509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anuran_Calls\n",
      "avila\n",
      "Cardiotocography\n",
      "credit card\n",
      "EEG\n",
      "HTRU2\n",
      "image\n",
      "landsat\n",
      "letter-recognition\n",
      "magic\n",
      "occupancy\n",
      "page-blocks\n",
      "pendigits\n",
      "shuttle\n",
      "Wall-following\n",
      "wifi_localization\n",
      "wine\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    make_normed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.511663Z",
     "iopub.status.busy": "2021-07-05T12:34:41.511663Z",
     "iopub.status.idle": "2021-07-05T12:34:41.674866Z",
     "shell.execute_reply": "2021-07-05T12:34:41.673908Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.511663Z"
    }
   },
   "outputs": [],
   "source": [
    "min_minor_class_ratio = 0.2\n",
    "\n",
    "for dataset in datasets:\n",
    "    save_path = os.path.join(INTERIM_DATA_DIR, dataset + '_bin.csv')\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    print('========================================================================')\n",
    "    print(dataset)\n",
    "    df = pd.read_csv(os.path.join(INTERIM_DATA_DIR, dataset + '_norm.csv'))\n",
    "    display(pd.DataFrame(df['label'].value_counts().sort_index().sort_values(ascending=False)).T)\n",
    "\n",
    "    tmp = df['label'].value_counts().sort_index().sort_values(ascending=False).cumsum()\n",
    "    tmp = tmp / tmp.max()\n",
    "    tmp = (tmp > (1 - min_minor_class_ratio)).astype(int)\n",
    "    tmp.iloc[0] = 0\n",
    "    df['__tmp'] = df['label'].copy()\n",
    "    for k, v in tmp.items():\n",
    "        df.loc[df['__tmp'] == k, 'label'] = v\n",
    "    df = df.drop(['__tmp'], axis=1)\n",
    "    df['label'] = df['label'].astype(bool).astype(int)\n",
    "    display(pd.DataFrame(df['label'].value_counts().sort_index()).T)\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.675868Z",
     "iopub.status.busy": "2021-07-05T12:34:41.674866Z",
     "iopub.status.idle": "2021-07-05T12:34:41.911859Z",
     "shell.execute_reply": "2021-07-05T12:34:41.911859Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.675868Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:41.911859Z",
     "iopub.status.busy": "2021-07-05T12:34:41.911859Z",
     "iopub.status.idle": "2021-07-05T12:34:42.047446Z",
     "shell.execute_reply": "2021-07-05T12:34:42.043242Z",
     "shell.execute_reply.started": "2021-07-05T12:34:41.911859Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validation(df, classifier=RandomForestClassifier):\n",
    "    X = df.values[:, :-1]\n",
    "    y = df.values[:, -1]\n",
    "\n",
    "    scoring = ['accuracy', 'balanced_accuracy', 'f1_macro', 'f1_micro']\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    clf = classifier(n_estimators=20, random_state=42)\n",
    "    results = cross_validate(clf, X, y, cv=cv, scoring=scoring, return_estimator=True)\n",
    "\n",
    "    scores = pd.DataFrame({k:results[k] for k in results.keys() if 'test' in k})\n",
    "\n",
    "    importances = [clf.feature_importances_ for clf in results['estimator']]\n",
    "    importances = pd.DataFrame(importances, columns=df.columns[:-1]).mean()\n",
    "    return importances, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:42.050664Z",
     "iopub.status.busy": "2021-07-05T12:34:42.050126Z",
     "iopub.status.idle": "2021-07-05T12:34:42.191481Z",
     "shell.execute_reply": "2021-07-05T12:34:42.190480Z",
     "shell.execute_reply.started": "2021-07-05T12:34:42.050664Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_irrelevant_features(df, irr_features, seed=0):\n",
    "    idx = np.arange(len(df))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    df_ = df.copy()\n",
    "    df_.iloc[:, irr_features] = df.iloc[idx, irr_features].values\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:42.193369Z",
     "iopub.status.busy": "2021-07-05T12:34:42.192277Z",
     "iopub.status.idle": "2021-07-05T12:34:42.360253Z",
     "shell.execute_reply": "2021-07-05T12:34:42.359309Z",
     "shell.execute_reply.started": "2021-07-05T12:34:42.192277Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_with_shuffle(df, importances, ratio=0.3, classifier=RandomForestClassifier):\n",
    "    feature_idx = importances.reset_index(drop=True).sort_values().index.values\n",
    "    n_irr_features = int(len(feature_idx) * ratio)\n",
    "    irr_features = feature_idx[:n_irr_features]\n",
    "    df = make_irrelevant_features(df, irr_features)\n",
    "    importances, scores = cross_validation(df, classifier)\n",
    "    return df, importances, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:42.361254Z",
     "iopub.status.busy": "2021-07-05T12:34:42.361254Z",
     "iopub.status.idle": "2021-07-05T12:34:42.507587Z",
     "shell.execute_reply": "2021-07-05T12:34:42.506579Z",
     "shell.execute_reply.started": "2021-07-05T12:34:42.361254Z"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    save_path = os.path.join(INTERIM_DATA_DIR, dataset + '_shuffled.csv')\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    print(dataset)\n",
    "    path = os.path.join(INTERIM_DATA_DIR, dataset + '_bin.csv')\n",
    "    df = pd.read_csv(path)\n",
    "    importances, scores = cross_validation(df)\n",
    "    df_shuffled, importances_shuffled, scores_shuffled = cv_with_shuffle(df, importances)\n",
    "    display(pd.DataFrame([scores.mean(), scores_shuffled.mean()]).round(3))\n",
    "    display(pd.DataFrame([importances, importances_shuffled]).round(3))\n",
    "    df_shuffled.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T12:34:42.508541Z",
     "iopub.status.busy": "2021-07-05T12:34:42.508541Z",
     "iopub.status.idle": "2021-07-05T12:34:43.420476Z",
     "shell.execute_reply": "2021-07-05T12:34:43.420476Z",
     "shell.execute_reply.started": "2021-07-05T12:34:42.508541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th># of instances</th>\n",
       "      <th># of features</th>\n",
       "      <th>Class ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anuran_Calls</td>\n",
       "      <td>7195</td>\n",
       "      <td>22</td>\n",
       "      <td>61.4% : 38.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avila</td>\n",
       "      <td>20867</td>\n",
       "      <td>10</td>\n",
       "      <td>78.3% : 21.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiotocography</td>\n",
       "      <td>2126</td>\n",
       "      <td>21</td>\n",
       "      <td>77.8% : 22.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit card</td>\n",
       "      <td>30000</td>\n",
       "      <td>13</td>\n",
       "      <td>77.9% : 22.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEG</td>\n",
       "      <td>14980</td>\n",
       "      <td>14</td>\n",
       "      <td>55.1% : 44.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HTRU2</td>\n",
       "      <td>17898</td>\n",
       "      <td>8</td>\n",
       "      <td>90.8% : 9.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>image</td>\n",
       "      <td>2310</td>\n",
       "      <td>19</td>\n",
       "      <td>71.4% : 28.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>landsat</td>\n",
       "      <td>6435</td>\n",
       "      <td>36</td>\n",
       "      <td>79.3% : 20.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>letter-recognition</td>\n",
       "      <td>20000</td>\n",
       "      <td>16</td>\n",
       "      <td>77.8% : 22.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>magic</td>\n",
       "      <td>19020</td>\n",
       "      <td>10</td>\n",
       "      <td>64.8% : 35.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>occupancy</td>\n",
       "      <td>20560</td>\n",
       "      <td>5</td>\n",
       "      <td>76.9% : 23.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>page-blocks</td>\n",
       "      <td>5473</td>\n",
       "      <td>10</td>\n",
       "      <td>89.8% : 10.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pendigits</td>\n",
       "      <td>10992</td>\n",
       "      <td>16</td>\n",
       "      <td>71.2% : 28.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>58000</td>\n",
       "      <td>9</td>\n",
       "      <td>78.6% : 21.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wall-following</td>\n",
       "      <td>5456</td>\n",
       "      <td>24</td>\n",
       "      <td>78.8% : 21.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wifi_localization</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>75.0% : 25.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wine</td>\n",
       "      <td>6497</td>\n",
       "      <td>11</td>\n",
       "      <td>76.6% : 23.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset  # of instances  # of features    Class ratio\n",
       "0         Anuran_Calls            7195             22  61.4% : 38.6%\n",
       "1                avila           20867             10  78.3% : 21.7%\n",
       "2     Cardiotocography            2126             21  77.8% : 22.2%\n",
       "3          credit card           30000             13  77.9% : 22.1%\n",
       "4                  EEG           14980             14  55.1% : 44.9%\n",
       "5                HTRU2           17898              8   90.8% : 9.2%\n",
       "6                image            2310             19  71.4% : 28.6%\n",
       "7              landsat            6435             36  79.3% : 20.7%\n",
       "8   letter-recognition           20000             16  77.8% : 22.2%\n",
       "9                magic           19020             10  64.8% : 35.2%\n",
       "10           occupancy           20560              5  76.9% : 23.1%\n",
       "11         page-blocks            5473             10  89.8% : 10.2%\n",
       "12           pendigits           10992             16  71.2% : 28.8%\n",
       "13             shuttle           58000              9  78.6% : 21.4%\n",
       "14      Wall-following            5456             24  78.8% : 21.2%\n",
       "15   wifi_localization            2000              7  75.0% : 25.0%\n",
       "16                wine            6497             11  76.6% : 23.4%"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(os.path.join(INTERIM_DATA_DIR, dataset+'_shuffled.csv'))\n",
    "    class_ratio = (df['label'].value_counts() / len(df['label'])) * 100\n",
    "    class_ratio = '%.1f%% : %.1f%%'%(class_ratio[0], class_ratio[1])\n",
    "    dfs.append([dataset, df.shape[0], df.shape[1]-1, class_ratio])\n",
    "df = pd.DataFrame(dfs, columns=['Dataset', '# of instances', '# of features', 'Class ratio'])\n",
    "df.to_latex(os.path.join(OUTPUT_DIR, 'dataset.txt'), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
